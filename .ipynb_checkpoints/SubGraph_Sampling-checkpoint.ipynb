{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e216df8-8ccd-4f76-a88a-5985ee1c0c0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msheaffmtl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_dig_sheaf_fmtl, run_ana_sheaf_fmtl\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_vehicle_data, read_school_data, read_har_data, read_gleam_data, count_model_parameters, MultinomialLogisticRegression, LinearRegression, generate_random_adjacency_matrix, cross_entropy_loss_with_l2, mse_loss_with_l2, TwoSectionH, seq_scheduling\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from sheaffmtl import run_dig_sheaf_fmtl, run_ana_sheaf_fmtl\n",
    "from utils import read_vehicle_data, read_school_data, read_har_data, read_gleam_data, count_model_parameters, MultinomialLogisticRegression, LinearRegression, generate_random_adjacency_matrix, cross_entropy_loss_with_l2, mse_loss_with_l2, TwoSectionH, seq_scheduling\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4e777-dfdd-474d-a183-1e135f0e33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Federated Learning Algorithms')\n",
    "    parser.add_argument('--dataset', type=str, required=True, help='Input data (vehicle or school)')\n",
    "    parser.add_argument('--algorithm', type=str, required=True, help='Algorithm name (dFedU or Sheaf-FL)')\n",
    "    parser.add_argument('--alpha', type=float, default=0.005, help='Learning rate to update the model of Sheaf-FMTL')\n",
    "    parser.add_argument('--eta', type=float, default=0.001, help='Learning rate to update the linear maps in Sheaf-FMTL')\n",
    "    parser.add_argument('--local_iterations', type=int, default=5, help='Number of local iterations for dFedU')\n",
    "    parser.add_argument('--local_lr', type=float, default=0.001, help='Local learning rate for dFedU')\n",
    "    parser.add_argument('--lambda-reg', type=float, default=0.001, help='Regularization strength')\n",
    "    parser.add_argument('--factor', type=float, default=0.3, help='Factor for P_ij matrix size for Sheaf-FMTL')\n",
    "    parser.add_argument('--num-rounds', type=int, default=200, help='Number of training rounds')\n",
    "    parser.add_argument('--scheme', type=str, default='dig', help='scheme: dig- Digital, ana-analog')\n",
    "    parser.add_argument('--power', type=float, default=0.1, help='Transmission power')\n",
    "    parser.add_argument('--N', type=int, default=5000, help='Number of resources in one block')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.dataset == 'vehicle':\n",
    "        client_train_datasets, client_test_datasets, input_size, num_classes = read_vehicle_data()\n",
    "        model = MultinomialLogisticRegression(input_size, num_classes)\n",
    "        loss_func = cross_entropy_loss_with_l2\n",
    "        metric_name = 'Accuracy'\n",
    "        metric_func = lambda targets, predictions: torch.mean((targets == predictions).float())\n",
    "    elif args.dataset == 'gleam':\n",
    "        client_train_datasets, client_test_datasets, input_size, num_classes = read_gleam_data()\n",
    "        model = MultinomialLogisticRegression(input_size, num_classes)\n",
    "        loss_func = cross_entropy_loss_with_l2\n",
    "        metric_name = 'Accuracy'\n",
    "        metric_func = lambda targets, predictions: torch.mean((targets == predictions).float())\n",
    "    elif args.dataset == 'har':\n",
    "        client_train_datasets, client_test_datasets, input_size, num_classes = read_har_data()\n",
    "        model = MultinomialLogisticRegression(input_size, num_classes)\n",
    "        loss_func = cross_entropy_loss_with_l2\n",
    "        metric_name = 'Accuracy'\n",
    "        metric_func = lambda targets, predictions: torch.mean((targets == predictions).float())\n",
    "    elif args.dataset == 'school':\n",
    "        client_train_datasets, client_test_datasets = read_school_data()\n",
    "        input_size = client_train_datasets[0][0][0].shape[0]\n",
    "        model = LinearRegression(input_size)\n",
    "        loss_func = mse_loss_with_l2\n",
    "        metric_name = 'MSE'\n",
    "        metric_func = nn.MSELoss()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset type.\")\n",
    "\n",
    "    num_clients = len(client_train_datasets)\n",
    "    print(f\"Number of clients {num_clients}\")\n",
    "    print(f\"Number of features {client_train_datasets[0][0][0].shape}\")\n",
    "\n",
    "    adjacency_matrix = generate_random_adjacency_matrix(num_clients)\n",
    "    neighbors = [np.nonzero(adjacency_matrix[i])[0].tolist() for i in range(num_clients)]\n",
    "    G = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "\n",
    "    # -------------------- Channels Preparations ----------------------\n",
    "    # Prepare the channels\n",
    "    P_bar = args.power\n",
    "    N = args.N\n",
    "    K = num_clients\n",
    "    d_min = 50\n",
    "    d_max = 200\n",
    "    Tmax = args.num_rounds\n",
    "    rho = d_min + (d_max - d_min) * np.random.rand(K, 1)\n",
    "    theta = 2 * np.pi * np.random.rand(K, 1)\n",
    "    D = np.sqrt(rho ** 2 + rho.T ** 2 - 2 * (rho @ rho.T) * np.cos(theta - theta.T))\n",
    "    # Fill in D[i,i] some non-zero value to avoid Inf in PL\n",
    "    for i in range(K):\n",
    "        if i:\n",
    "            D[i, i] = D[i, i - 1]\n",
    "        else:\n",
    "            D[i, i] = D[i, i + 1]\n",
    "    A0 = 10 ** (-3.35)\n",
    "    d0 = 1\n",
    "    gamma = 3.76\n",
    "    PL = A0 * ((D / d0) ** (-gamma))\n",
    "    # Generate random channels for unblocked edges of the given graph\n",
    "    np.random.seed(10)\n",
    "    CH_gen = np.random.randn(Tmax, K, K) / np.sqrt(2) + 1j * np.random.randn(Tmax, K, K) / np.sqrt(2)\n",
    "    d = count_model_parameters(model)\n",
    "\n",
    "    if args.scheme == 'dig':\n",
    "        _, from_node_to_color_id = TwoSectionH(G)\n",
    "        Chi = max(from_node_to_color_id.values()) + 1\n",
    "    elif args.scheme == 'ana':\n",
    "        schedule_list, Tx_times = seq_scheduling(G.copy())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transmission scheme\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if args.algorithm == 'dFedU':\n",
    "        average_test_metrics, transmitted_bits_per_iteration, resource_blocks_per_learning_round = run_dfedu(\n",
    "            client_train_datasets,\n",
    "            client_test_datasets,\n",
    "            args.num_rounds,\n",
    "            args.local_iterations,\n",
    "            args.local_lr,\n",
    "            neighbors,\n",
    "            args.lambda_reg,\n",
    "            model,\n",
    "            loss_func,\n",
    "            metric_func,\n",
    "            metric_name,\n",
    "            G, K, CH_gen, PL, Chi, P_bar, N,\n",
    "            d\n",
    "    )\n",
    "    elif args.algorithm == 'Sheaf-FMTL' and args.scheme == 'dig':\n",
    "        average_test_metrics, transmitted_bits_per_iteration, resource_blocks_per_learning_round = run_dig_sheaf_fmtl(\n",
    "            client_train_datasets, \n",
    "            client_test_datasets, \n",
    "            args.num_rounds, \n",
    "            args.alpha, \n",
    "            args.eta, \n",
    "            args.lambda_reg, \n",
    "            args.factor, \n",
    "            adjacency_matrix,\n",
    "            model, \n",
    "            loss_func,\n",
    "            metric_func,\n",
    "            metric_name,\n",
    "            G,\n",
    "            K,\n",
    "            CH_gen,\n",
    "            PL,\n",
    "            Chi,\n",
    "            P_bar,\n",
    "            N,\n",
    "            d\n",
    "        )\n",
    "    elif args.algorithm == 'Sheaf-FMTL' and args.scheme == 'ana':\n",
    "        average_test_metrics, transmitted_bits_per_iteration, resource_blocks_per_learning_round = run_ana_sheaf_fmtl(\n",
    "            client_train_datasets,\n",
    "            client_test_datasets,\n",
    "            args.num_rounds,\n",
    "            args.alpha,\n",
    "            args.eta,\n",
    "            args.lambda_reg,\n",
    "            args.factor,\n",
    "            adjacency_matrix,\n",
    "            model,\n",
    "            loss_func,\n",
    "            metric_func,\n",
    "            metric_name,\n",
    "            G,\n",
    "            K,\n",
    "            CH_gen,\n",
    "            PL,\n",
    "            schedule_list,\n",
    "            Tx_times,\n",
    "            P_bar,\n",
    "            N,\n",
    "            d\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid algorithm. Choose either \"dFedU\" or \"Sheaf-FL\".')\n",
    "\n",
    "    print(f'Average Test {metric_name}s:', average_test_metrics)\n",
    "    print('Transmitted Bits per Iteration:', transmitted_bits_per_iteration)\n",
    "    print('Number of users Resource Blocks', resource_blocks_per_learning_round)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
